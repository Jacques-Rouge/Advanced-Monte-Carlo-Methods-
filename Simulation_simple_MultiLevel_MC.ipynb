{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "697a2863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Multilevel Monte Carlo Implementation\n",
    "# Following Giles (2015) algorithm for European option pricing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29603563",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SDE Coefficients\n",
    "\n",
    "def mu_S(S, M):\n",
    "    \"\"\"Drift coefficient for S process\"\"\"\n",
    "    return 0.1 * (np.sqrt(np.minimum(M, S)) - 1) * S\n",
    "\n",
    "def sigma_S(S):\n",
    "    \"\"\"Diffusion coefficient for S process\"\"\"\n",
    "    return 0.5 * S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4c244bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MLMC Configuration\n",
    "\n",
    "T = 1.0              # Time horizon\n",
    "K = 1.0              # Strike price\n",
    "M_param = 4.0        # SDE parameter\n",
    "epsilon = 0.0001     # Target accuracy\n",
    "max_levels = 10      # Maximum number of levels\n",
    "N_initial = 10000    # Initial samples per new level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3908758",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MLMC Simulation Functions\n",
    "\n",
    "def euler_maruyama(N, M, S0, mu_func, sigma_func, M_param, T):\n",
    "    \"\"\"\n",
    "    Euler-Maruyama scheme for SDE simulation\n",
    "    \n",
    "    Args:\n",
    "        N: Number of paths\n",
    "        M: Number of time steps\n",
    "        S0: Initial value\n",
    "        mu_func: Drift function\n",
    "        sigma_func: Diffusion function\n",
    "        M_param: SDE parameter\n",
    "        T: Time horizon\n",
    "        \n",
    "    Returns:\n",
    "        Terminal values S(T) for all paths\n",
    "    \"\"\"\n",
    "    dt = T / M\n",
    "    DW = np.sqrt(dt) * np.random.randn(N, M)\n",
    "    S = np.full(N, S0)\n",
    "    \n",
    "    for i in range(M):\n",
    "        mu = mu_func(S, M_param)\n",
    "        sigma = sigma_func(S)\n",
    "        S += mu * dt + sigma * DW[:, i]\n",
    "        S = np.maximum(S, 1e-10)  # Prevent negative values\n",
    "    \n",
    "    return S\n",
    "\n",
    "\n",
    "def mlmc_level(N, M, mu_func, sigma_func, M_param, T, K):\n",
    "    \"\"\"\n",
    "    Simulate single MLMC level (for L=0)\n",
    "    \n",
    "    Returns:\n",
    "        mean: E[payoff]\n",
    "        var: Var[payoff]\n",
    "    \"\"\"\n",
    "    S_T = euler_maruyama(N, M, 1.0, mu_func, sigma_func, M_param, T)\n",
    "    payoff = np.maximum(S_T - K, 0)\n",
    "    return np.mean(payoff), np.var(payoff)\n",
    "\n",
    "\n",
    "def mlmc_level_diff(N, M_coarse, M_fine, mu_func, sigma_func, M_param, T, K):\n",
    "    \"\"\"\n",
    "    Simulate MLMC level difference (for L>0)\n",
    "    \n",
    "    Uses same Brownian motion for coarse and fine paths (telescoping)\n",
    "    \n",
    "    Returns:\n",
    "        mean_diff: E[P_fine - P_coarse]\n",
    "        var_diff: Var[P_fine - P_coarse]\n",
    "    \"\"\"\n",
    "    dt_fine = T / M_fine\n",
    "    dt_coarse = T / M_coarse\n",
    "    ratio = M_fine // M_coarse\n",
    "    \n",
    "    # Generate fine Brownian increments\n",
    "    DW_fine = np.sqrt(dt_fine) * np.random.randn(N, M_fine)\n",
    "    \n",
    "    # Aggregate to coarse Brownian (same underlying motion)\n",
    "    DW_coarse = np.zeros((N, M_coarse))\n",
    "    for j in range(M_coarse):\n",
    "        DW_coarse[:, j] = np.sum(DW_fine[:, j*ratio:(j+1)*ratio], axis=1)\n",
    "    \n",
    "    # Simulate fine path\n",
    "    S_fine = np.ones(N)\n",
    "    for i in range(M_fine):\n",
    "        mu = mu_func(S_fine, M_param)\n",
    "        sigma = sigma_func(S_fine)\n",
    "        S_fine += mu * dt_fine + sigma * DW_fine[:, i]\n",
    "        S_fine = np.maximum(S_fine, 1e-10)\n",
    "    \n",
    "    # Simulate coarse path (same Brownian)\n",
    "    S_coarse = np.ones(N)\n",
    "    for i in range(M_coarse):\n",
    "        mu = mu_func(S_coarse, M_param)\n",
    "        sigma = sigma_func(S_coarse)\n",
    "        S_coarse += mu * dt_coarse + sigma * DW_coarse[:, i]\n",
    "        S_coarse = np.maximum(S_coarse, 1e-10)\n",
    "    \n",
    "    # Payoff difference\n",
    "    P_fine = np.maximum(S_fine - K, 0)\n",
    "    P_coarse = np.maximum(S_coarse - K, 0)\n",
    "    diff = P_fine - P_coarse\n",
    "    \n",
    "    return np.mean(diff), np.var(diff)\n",
    "\n",
    "\n",
    "def compute_optimal_samples(variances, M_levels, T, epsilon):\n",
    "    \"\"\"\n",
    "    Compute optimal sample allocation using Giles' formula\n",
    "    \n",
    "    N_l = ceil((2/ε²) × √(V_l × h_l) × Σ√(V_j / h_j))\n",
    "    \n",
    "    Args:\n",
    "        variances: List of variances [V_0, ..., V_L]\n",
    "        M_levels: List of time steps [M_0, ..., M_L]\n",
    "        T: Time horizon\n",
    "        epsilon: Target accuracy\n",
    "        \n",
    "    Returns:\n",
    "        List of optimal sample sizes [N_0, ..., N_L]\n",
    "    \"\"\"\n",
    "    h_levels = [T / M for M in M_levels]\n",
    "    sum_term = sum(np.sqrt(variances[j] / h_levels[j]) for j in range(len(variances)))\n",
    "    \n",
    "    N_optimal = []\n",
    "    for l in range(len(variances)):\n",
    "        N_l = int(np.ceil((2 / epsilon**2) * np.sqrt(variances[l] * h_levels[l]) * sum_term))\n",
    "        N_optimal.append(N_l)\n",
    "    \n",
    "    return N_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MULTILEVEL MONTE CARLO\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LEVEL L = 0\n",
      "======================================================================\n",
      "Step 2: Initial sampling (N=10000, M=1)\n",
      "  E[P_0] = 0.199706, Var[P_0] = 0.157442\n",
      "\n",
      "Step 3: Optimal sample allocation\n",
      "  Level 0: N_opt = 31,488,377 (current = 10,000)\n",
      "\n",
      "Step 4: Adding extra samples\n",
      "  Level 0: +31,478,377 samples\n",
      "\n",
      "======================================================================\n",
      "LEVEL L = 1\n",
      "======================================================================\n",
      "Step 2: Initial sampling (N=10000, M_c=1, M_f=4)\n",
      "  E[P_1 - P_0] = 0.000849, Var = 0.000106\n",
      "\n",
      "Step 3: Optimal sample allocation\n",
      "  Level 0: N_opt = 33,123,335 (current = 31,488,377)\n",
      "  Level 1: N_opt = 429,963 (current = 10,000)\n",
      "\n",
      "Step 4: Adding extra samples\n",
      "  Level 0: +1,634,958 samples\n",
      "  Level 1: +419,963 samples\n",
      "\n",
      "======================================================================\n",
      "LEVEL L = 2\n",
      "======================================================================\n",
      "Step 2: Initial sampling (N=10000, M_c=4, M_f=16)\n",
      "  E[P_2 - P_1] = 0.000809, Var = 0.000081\n",
      "\n",
      "Step 3: Optimal sample allocation\n",
      "  Level 0: N_opt = 35,980,607 (current = 33,123,335)\n",
      "  Level 1: N_opt = 467,052 (current = 429,963)\n",
      "  Level 2: N_opt = 204,057 (current = 10,000)\n",
      "\n",
      "Step 4: Adding extra samples\n",
      "  Level 0: +2,857,272 samples\n",
      "  Level 1: +37,089 samples\n",
      "  Level 2: +194,057 samples\n",
      "\n",
      "Step 5: Convergence test\n",
      "  |E[P_2 - P_1]| = 9.958358e-04\n",
      "  Threshold = 3.535534e-05\n",
      "\n",
      "======================================================================\n",
      "LEVEL L = 3\n",
      "======================================================================\n",
      "Step 2: Initial sampling (N=10000, M_c=16, M_f=64)\n",
      "  E[P_3 - P_2] = 0.000802, Var = 0.000052\n",
      "\n",
      "Step 3: Optimal sample allocation\n",
      "  Level 0: N_opt = 40,571,979 (current = 35,980,607)\n",
      "  Level 1: N_opt = 526,651 (current = 467,052)\n",
      "  Level 2: N_opt = 230,096 (current = 204,057)\n",
      "  Level 3: N_opt = 92,436 (current = 10,000)\n",
      "\n",
      "Step 4: Adding extra samples\n",
      "  Level 0: +4,591,372 samples\n",
      "  Level 1: +59,599 samples\n",
      "  Level 2: +26,039 samples\n",
      "  Level 3: +82,436 samples\n",
      "\n",
      "Step 5: Convergence test\n",
      "  |E[P_3 - P_2]| = 8.220451e-04\n",
      "  Threshold = 3.535534e-05\n",
      "\n",
      "======================================================================\n",
      "LEVEL L = 4\n",
      "======================================================================\n",
      "Step 2: Initial sampling (N=10000, M_c=64, M_f=256)\n",
      "  E[P_4 - P_3] = 0.000445, Var = 0.000017\n",
      "\n",
      "Step 3: Optimal sample allocation\n",
      "  Level 0: N_opt = 45,753,320 (current = 40,571,979)\n",
      "  Level 1: N_opt = 593,908 (current = 526,651)\n",
      "  Level 2: N_opt = 259,481 (current = 230,096)\n",
      "  Level 3: N_opt = 104,241 (current = 92,436)\n",
      "  Level 4: N_opt = 29,409 (current = 10,000)\n",
      "\n",
      "Step 4: Adding extra samples\n",
      "  Level 0: +5,181,341 samples\n",
      "  Level 1: +67,257 samples\n",
      "  Level 2: +29,385 samples\n",
      "  Level 3: +11,805 samples\n",
      "  Level 4: +19,409 samples\n",
      "\n",
      "Step 5: Convergence test\n",
      "  |E[P_4 - P_3]| = 4.751611e-04\n",
      "  Threshold = 3.535534e-05\n",
      "\n",
      "======================================================================\n",
      "LEVEL L = 5\n",
      "======================================================================\n",
      "Step 2: Initial sampling (N=10000, M_c=256, M_f=1024)\n",
      "  E[P_5 - P_4] = 0.000305, Var = 0.000006\n",
      "\n",
      "Step 3: Optimal sample allocation\n",
      "  Level 0: N_opt = 51,740,804 (current = 45,753,320)\n",
      "  Level 1: N_opt = 671,629 (current = 593,908)\n",
      "  Level 2: N_opt = 293,437 (current = 259,481)\n",
      "  Level 3: N_opt = 117,882 (current = 104,241)\n",
      "  Level 4: N_opt = 33,258 (current = 29,409)\n",
      "  Level 5: N_opt = 9,608 (current = 10,000)\n",
      "\n",
      "Step 4: Adding extra samples\n",
      "  Level 0: +5,987,484 samples\n",
      "  Level 1: +77,721 samples\n",
      "  Level 2: +33,956 samples\n",
      "  Level 3: +13,641 samples\n",
      "  Level 4: +3,849 samples\n",
      "\n",
      "Step 5: Convergence test\n",
      "  |E[P_5 - P_4]| = 3.052777e-04\n",
      "  Threshold = 3.535534e-05\n",
      "\n",
      "======================================================================\n",
      "LEVEL L = 6\n",
      "======================================================================\n",
      "Step 2: Initial sampling (N=10000, M_c=1024, M_f=4096)\n",
      "  E[P_6 - P_5] = 0.000158, Var = 0.000001\n",
      "\n",
      "Step 3: Optimal sample allocation\n",
      "  Level 0: N_opt = 57,763,543 (current = 51,740,804)\n",
      "  Level 1: N_opt = 749,808 (current = 671,629)\n",
      "  Level 2: N_opt = 327,594 (current = 293,437)\n",
      "  Level 3: N_opt = 131,604 (current = 117,882)\n",
      "  Level 4: N_opt = 37,129 (current = 33,258)\n",
      "  Level 5: N_opt = 10,727 (current = 10,000)\n",
      "  Level 6: N_opt = 2,698 (current = 10,000)\n",
      "\n",
      "Step 4: Adding extra samples\n",
      "  Level 0: +6,022,739 samples\n",
      "  Level 1: +78,179 samples\n",
      "  Level 2: +34,157 samples\n",
      "  Level 3: +13,722 samples\n",
      "  Level 4: +3,871 samples\n",
      "  Level 5: +727 samples\n",
      "\n",
      "Step 5: Convergence test\n",
      "  |E[P_6 - P_5]| = 1.577755e-04\n",
      "  Threshold = 3.535534e-05\n",
      "\n",
      "======================================================================\n",
      "LEVEL L = 7\n",
      "======================================================================\n",
      "Step 2: Initial sampling (N=10000, M_c=4096, M_f=16384)\n",
      "  E[P_7 - P_6] = 0.000083, Var = 0.000000\n",
      "\n",
      "Step 3: Optimal sample allocation\n",
      "  Level 0: N_opt = 64,159,360 (current = 57,763,543)\n",
      "  Level 1: N_opt = 832,830 (current = 749,808)\n",
      "  Level 2: N_opt = 363,866 (current = 327,594)\n",
      "  Level 3: N_opt = 146,175 (current = 131,604)\n",
      "  Level 4: N_opt = 41,240 (current = 37,129)\n",
      "  Level 5: N_opt = 11,914 (current = 10,727)\n",
      "  Level 6: N_opt = 2,997 (current = 10,000)\n",
      "  Level 7: N_opt = 796 (current = 10,000)\n",
      "\n",
      "Step 4: Adding extra samples\n",
      "  Level 0: +6,395,817 samples\n",
      "  Level 1: +83,022 samples\n",
      "  Level 2: +36,272 samples\n",
      "  Level 3: +14,571 samples\n",
      "  Level 4: +4,111 samples\n",
      "  Level 5: +1,187 samples\n",
      "\n",
      "Step 5: Convergence test\n",
      "  |E[P_7 - P_6]| = 8.269411e-05\n",
      "  Threshold = 3.535534e-05\n",
      "\n",
      "======================================================================\n",
      "LEVEL L = 8\n",
      "======================================================================\n",
      "Step 2: Initial sampling (N=10000, M_c=16384, M_f=65536)\n",
      "  E[P_8 - P_7] = 0.000036, Var = 0.000000\n",
      "\n",
      "Step 3: Optimal sample allocation\n",
      "  Level 0: N_opt = 70,152,695 (current = 64,159,360)\n",
      "  Level 1: N_opt = 910,628 (current = 832,830)\n",
      "  Level 2: N_opt = 397,856 (current = 363,866)\n",
      "  Level 3: N_opt = 159,830 (current = 146,175)\n",
      "  Level 4: N_opt = 45,092 (current = 41,240)\n",
      "  Level 5: N_opt = 13,027 (current = 11,914)\n",
      "  Level 6: N_opt = 3,276 (current = 10,000)\n",
      "  Level 7: N_opt = 870 (current = 10,000)\n",
      "  Level 8: N_opt = 204 (current = 10,000)\n",
      "\n",
      "Step 4: Adding extra samples\n",
      "  Level 0: +5,993,335 samples\n",
      "  Level 1: +77,798 samples\n",
      "  Level 2: +33,990 samples\n",
      "  Level 3: +13,655 samples\n",
      "  Level 4: +3,852 samples\n",
      "  Level 5: +1,113 samples\n",
      "\n",
      "Step 5: Convergence test\n",
      "  |E[P_8 - P_7]| = 3.625324e-05\n",
      "  Threshold = 3.535534e-05\n",
      "\n",
      "======================================================================\n",
      "LEVEL L = 9\n",
      "======================================================================\n",
      "Step 2: Initial sampling (N=10000, M_c=65536, M_f=262144)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 19.5 GiB for an array with shape (10000, 262144) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[241]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     35\u001b[39m M_levels.append(M_fine)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStep 2: Initial sampling (N=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_initial\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, M_c=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM_coarse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, M_f=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM_fine\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m mean_diff, var_diff = \u001b[43mmlmc_level_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_coarse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_fine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mmu_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_param\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m means_sum.append(mean_diff * N_initial)\n\u001b[32m     42\u001b[39m variances.append(var_diff)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[240]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mmlmc_level_diff\u001b[39m\u001b[34m(N, M_coarse, M_fine, mu_func, sigma_func, M_param, T, K)\u001b[39m\n\u001b[32m     57\u001b[39m ratio = M_fine // M_coarse\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Generate fine Brownian increments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m DW_fine = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt_fine\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_fine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Aggregate to coarse Brownian (same underlying motion)\u001b[39;00m\n\u001b[32m     63\u001b[39m DW_coarse = np.zeros((N, M_coarse))\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 19.5 GiB for an array with shape (10000, 262144) and data type float64"
     ]
    }
   ],
   "source": [
    "### MLMC Algorithm (Giles 2015)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MULTILEVEL MONTE CARLO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize\n",
    "L = 0\n",
    "M_levels = []\n",
    "means_sum = []\n",
    "variances = []\n",
    "N_current = []\n",
    "converged = False\n",
    "\n",
    "while L < max_levels and not converged:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"LEVEL L = {L}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Step 2: Estimate variance with initial samples\n",
    "    if L == 0:\n",
    "        M = 1\n",
    "        M_levels.append(M)\n",
    "        print(f\"Step 2: Initial sampling (N={N_initial}, M=1)\")\n",
    "        \n",
    "        mean, var = mlmc_level(N_initial, M, mu_S, sigma_S, M_param, T, K)\n",
    "        means_sum.append(mean * N_initial)\n",
    "        variances.append(var)\n",
    "        N_current.append(N_initial)\n",
    "        \n",
    "        print(f\"  E[P_0] = {mean:.6f}, Var[P_0] = {var:.6f}\")\n",
    "    else:\n",
    "        M_coarse = 4**(L-1)\n",
    "        M_fine = 4**L\n",
    "        M_levels.append(M_fine)\n",
    "        \n",
    "        print(f\"Step 2: Initial sampling (N={N_initial}, M_c={M_coarse}, M_f={M_fine})\")\n",
    "        \n",
    "        mean_diff, var_diff = mlmc_level_diff(N_initial, M_coarse, M_fine, \n",
    "                                               mu_S, sigma_S, M_param, T, K)\n",
    "        means_sum.append(mean_diff * N_initial)\n",
    "        variances.append(var_diff)\n",
    "        N_current.append(N_initial)\n",
    "        \n",
    "        print(f\"  E[P_{L} - P_{L-1}] = {mean_diff:.6f}, Var = {var_diff:.6f}\")\n",
    "    \n",
    "    # Step 3: Compute optimal samples for all levels\n",
    "    print(f\"\\nStep 3: Optimal sample allocation\")\n",
    "    N_optimal = compute_optimal_samples(variances, M_levels, T, epsilon)\n",
    "    \n",
    "    for l in range(L+1):\n",
    "        print(f\"  Level {l}: N_opt = {N_optimal[l]:,} (current = {N_current[l]:,})\")\n",
    "    \n",
    "    # Step 4: Add extra samples as needed\n",
    "    print(f\"\\nStep 4: Adding extra samples\")\n",
    "    for l in range(L+1):\n",
    "        N_extra = N_optimal[l] - N_current[l]\n",
    "        \n",
    "        if N_extra > 0:\n",
    "            print(f\"  Level {l}: +{N_extra:,} samples\")\n",
    "            \n",
    "            if l == 0:\n",
    "                mean_extra, _ = mlmc_level(N_extra, M_levels[0], mu_S, sigma_S, M_param, T, K)\n",
    "                means_sum[l] += mean_extra * N_extra\n",
    "            else:\n",
    "                M_c = M_levels[l-1]\n",
    "                M_f = M_levels[l]\n",
    "                mean_extra, _ = mlmc_level_diff(N_extra, M_c, M_f, mu_S, sigma_S, M_param, T, K)\n",
    "                means_sum[l] += mean_extra * N_extra\n",
    "            \n",
    "            N_current[l] = N_optimal[l]\n",
    "    \n",
    "    # Step 5: Test convergence (L ≥ 2)\n",
    "    if L >= 2:\n",
    "        mean_L = means_sum[L] / N_current[L]\n",
    "        threshold = 0.5 * epsilon / np.sqrt(2)\n",
    "        \n",
    "        print(f\"\\nStep 5: Convergence test\")\n",
    "        print(f\"  |E[P_{L} - P_{L-1}]| = {abs(mean_L):.6e}\")\n",
    "        print(f\"  Threshold = {threshold:.6e}\")\n",
    "        \n",
    "        if abs(mean_L) < threshold:\n",
    "            converged = True\n",
    "            print(f\"  ✓ CONVERGED\")\n",
    "    \n",
    "    # Step 6: Continue to next level\n",
    "    if not converged:\n",
    "        L += 1\n",
    "\n",
    "# Final estimator\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "V_mlmc = sum(means_sum[l] / N_current[l] for l in range(len(means_sum)))\n",
    "total_samples = sum(N_current)\n",
    "\n",
    "print(f\"\\nOption Price: {V_mlmc:.6f}\")\n",
    "print(f\"Levels: {len(means_sum)}\")\n",
    "print(f\"Total samples: {total_samples:,}\")\n",
    "print(f\"Epsilon: {epsilon}\")\n",
    "print(f\"\\nSample distribution:\")\n",
    "for l in range(len(N_current)):\n",
    "    print(f\"  Level {l}: {N_current[l]:,} samples\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1757fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
